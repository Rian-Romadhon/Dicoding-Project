# -*- coding: utf-8 -*-
"""Submission NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FPG5NgEGT3vf3dtBtEb_WwP9uzp6cbmU

##**Submission NLP**

Saya akan membuat prediksi genre (komedi, horor, action) suatu film berdasarkan plot yang disediakan. Untuk datasetnya, saya mengambil dari https://www.kaggle.com/jrobischon/wikipedia-movie-plots
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
df = pd.read_csv('/content/drive/My Drive/wiki_movie_plots_deduped.csv')

#melihat jumlah data
df.info()

#saya hanya memerlukan kolom Genre dengan Plot
df = df[['Genre', 'Plot']]

#kemudian mari kita lihat persebaran genre
df['Genre'].value_counts()

#saya hanya akan memilih 3 genre saja yaitu comedy, horror, dan action
label = ['comedy', 'horror', 'action']
movie = df[df['Genre'].isin(label)].reset_index()

#jika dilihat dari persebaran genre, genre comedy memiliki jumlah yang lebih besar (tidak seimbang)
#oleh karena itu saya ingin menyamakan jumlah semua genre masing-masing 1000
comedy = movie[movie['Genre']=='comedy'].iloc[:1000]
horror = movie[movie['Genre']=='horror'].iloc[:1000]
action = movie[movie['Genre']=='action'].iloc[:1000]

clean_movie = pd.concat([comedy,horror,action], ignore_index=True)
clean_movie = clean_movie[['Plot','Genre']]

#karena label berupa data kategorikal maka harus dilakukan one hot encoding terlebih dahulu
category = pd.get_dummies(clean_movie['Genre'])
movie_new = pd.concat([clean_movie, category], axis=1)
movie_new = movie_new.drop(columns='Genre')
movie_new.head()

#setelah data sudah bersih saatnya membagi data menjadi data latih dan data test

from sklearn.model_selection import train_test_split
X = movie_new['Plot'].values
y = movie_new.drop(columns='Plot').values

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)

#selanjutnya mengubah kata dalam plot menjadi numerik dan melakukan normalisasi
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

tokenizer = Tokenizer(num_words=8500, oov_token='x')
tokenizer.fit_on_texts(X_train)
tokenizer.fit_on_texts(X_test)

#transform
train_seq = tokenizer.texts_to_sequences(X_train)
test_seq  = tokenizer.texts_to_sequences(X_test)

#normalisasi
train_pad = pad_sequences(train_seq)
test_pad  = pad_sequences(test_seq)

#callback
import tensorflow as tf

class Callback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
      if(logs.get('accuracy')>0.95):
        print("\nAkurasi telah mencapai >95%!")
        self.model.stop_training = True
callback = Callback()

#selanjutnya membuat model kemudian melatih model

import tensorflow as tf
model = tf.keras.Sequential([
                              tf.keras.layers.Embedding(input_dim=8500, output_dim=16),
                              tf.keras.layers.LSTM(64),
                              tf.keras.layers.Dense(256, activation='relu'),
                              tf.keras.layers.Dropout(0.5),
                              tf.keras.layers.Dense(128, activation='relu'),
                              tf.keras.layers.Dropout(0.5),
                              tf.keras.layers.Dense(64),
                              tf.keras.layers.Dense(3, activation='softmax')
                            ])
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])
history = model.fit(train_pad, y_train, epochs=30, 
                    validation_data=(test_pad, y_test), verbose=2, callbacks=[callback])

#plot akurasi
import matplotlib.pyplot as plt

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss=history.history['loss']
val_loss=history.history['val_loss']

epochs_range = range(4) 
plt.figure(figsize=(10, 10))

#visualisasi training and validation accurancy
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

#visualisasi training and validation loss 
plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

